{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "211f6c43-17b1-42c4-8174-f96f1dc96e6a",
   "metadata": {},
   "source": [
    "## Year 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194d0a0e-e4d3-4475-992c-13618513ca14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import pandas as pd\n",
    "import csv \n",
    "\n",
    "# Read DEVICE data for 2021 \n",
    "device_data = pd.read_csv(\"DEVICE2021.txt\", delimiter=\"|\", encoding=\"latin1\", on_bad_lines='skip')\n",
    "\n",
    "# Read FOI_TEXT data for 2021\n",
    "foitext_data = pd.read_csv(\"foitext2021.txt\", delimiter=\"|\", encoding=\"latin1\")\n",
    "# Filter for pacemaker medical devices\n",
    "pacemaker_devices = device_data[device_data['GENERIC_NAME'].str.contains('pacemaker', case=False, na=False)]\n",
    "\n",
    "# Merge datasets on MDR_REPORT_KEY\n",
    "merged_data = pd.merge(pacemaker_devices, foitext_data, on='MDR_REPORT_KEY', how='inner')\n",
    "\n",
    "# Drop duplicates based on MDR_REPORT_KEY\n",
    "merged_data = merged_data.drop_duplicates(subset='MDR_REPORT_KEY')\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['DEVICE_EVENT_KEY', 'IMPLANT_FLAG', 'DATE_REMOVED_FLAG', 'MANUFACTURER_D_ZIP_CODE_EXT', 'OTHER_ID_NUMBER', 'DATE_RETURNED_TO_MANUFACTURER', 'MANUFACTURER_D_ADDRESS_2', 'DATE_REPORT', 'PATIENT_SEQUENCE_NUMBER', 'LOT_NUMBER']\n",
    "\n",
    "# Drop specified columns\n",
    "merged_data = merged_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Save CSV file\n",
    "merged_data.to_csv('merged_data_cleaned_2021.csv', index=False)\n",
    "\n",
    "print(\"Dataset for 2021 saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d32526-30b1-45e4-89a5-8d1abfefe5fe",
   "metadata": {},
   "source": [
    "## Year 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64ae32e-b6fc-4e7a-a947-ac5a434a69a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import pandas as pd\n",
    "import csv \n",
    "\n",
    "# Read DEVICE data for 2022 \n",
    "device_data = pd.read_csv(\"DEVICE2022.txt\", delimiter=\"|\", encoding=\"latin1\", on_bad_lines='skip')\n",
    "\n",
    "# Display the first few rows \n",
    "print(\"DEVICE Data Sample:\")\n",
    "print(device_data.head())\n",
    "# Read the FOI_TEXT data for 2022\n",
    "foitext_data = pd.read_csv(\"foitext2022.txt\", delimiter=\"|\", encoding=\"latin1\")\n",
    "\n",
    "# Display the first few rows \n",
    "print(\"\\nFOI_TEXT Data Sample:\")\n",
    "print(foitext_data.head())\n",
    "# Filter for pacemaker medical devices\n",
    "pacemaker_devices = device_data[device_data['GENERIC_NAME'].str.contains('pacemaker', case=False, na=False)]\n",
    "\n",
    "# Merge datasets on MDR_REPORT_KEY\n",
    "merged_data = pd.merge(pacemaker_devices, foitext_data, on='MDR_REPORT_KEY', how='inner')\n",
    "\n",
    "# Drop duplicates based on MDR_REPORT_KEY\n",
    "merged_data = merged_data.drop_duplicates(subset='MDR_REPORT_KEY')\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['DEVICE_EVENT_KEY', 'IMPLANT_FLAG', 'DATE_REMOVED_FLAG', 'MANUFACTURER_D_ZIP_CODE_EXT', 'OTHER_ID_NUMBER', 'DATE_RETURNED_TO_MANUFACTURER', 'MANUFACTURER_D_ADDRESS_2', 'DATE_REPORT', 'PATIENT_SEQUENCE_NUMBER', 'LOT_NUMBER']\n",
    "\n",
    "# Drop specified columns\n",
    "merged_data = merged_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Save  CSV file\n",
    "merged_data.to_csv('merged_data_cleaned_2022.csv', index=False)\n",
    "\n",
    "print(\"Dataset for 2022 saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad931f02-34e2-484f-afac-0f95b3fee9aa",
   "metadata": {},
   "source": [
    "## Year 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a02917-c148-43f2-b77a-05b40be0ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv \n",
    "\n",
    "# Read the DEVICE data\n",
    "device_data = pd.read_csv(\"DEVICE2023.txt\", delimiter=\"|\", encoding=\"latin1\")\n",
    "\n",
    "# Read the FOI_TEXT data\n",
    "foitext_data = pd.read_csv(\"foitext2023.txt\", delimiter=\"|\", encoding=\"latin1\")\n",
    "# Display the first few rows\n",
    "print(\"DEVICE Data Sample:\")\n",
    "print(device_data.head())\n",
    "print(\"\\nFOI_TEXT Data Sample:\")\n",
    "print(foitext_data.head())\n",
    "# Filter for pacemaker medical devices\n",
    "pacemaker_devices = device_data[device_data['GENERIC_NAME'].str.contains('pacemaker', case=False, na=False)]\n",
    "# Merge datasets on MDR_REPORT_KEY\n",
    "merged_data = pd.merge(pacemaker_devices, foitext_data, on='MDR_REPORT_KEY', how='inner')\n",
    "\n",
    "# Drop duplicates based on MDR_REPORT_KEY\n",
    "merged_data = merged_data.drop_duplicates(subset='MDR_REPORT_KEY')\n",
    "\n",
    "# Display merged data sample after removing duplicates\n",
    "print(\"\\nMerged Data Sample (After Removing Duplicates):\")\n",
    "print(merged_data.head())\n",
    "\n",
    "# List of columns to remove\n",
    "columns_to_remove = ['DATE_REMOVED_FLAG', 'MANUFACTURER_D_ZIP_CODE_EXT', 'OTHER_ID_NUMBER', 'DATE_RETURNED_TO_MANUFACTURER', 'MANUFACTURER_D_ADDRESS_2', 'DATE_REPORT', 'PATIENT_SEQUENCE_NUMBER', 'LOT_NUMBER']\n",
    "\n",
    "# Drop specified columns\n",
    "merged_data = merged_data.drop(columns=columns_to_remove, errors='ignore')\n",
    "\n",
    "# Save merged_data to a CSV file\n",
    "merged_data.to_csv('merged_data_cleaned.csv', index=False)\n",
    "\n",
    "print(\"Dataset saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6960e1-28b3-4325-9cc0-d5db81ba20bb",
   "metadata": {},
   "source": [
    "## Combined all 3 years "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e51726f-cbfd-49f5-94fb-bb2243f10fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the cleaned datasets\n",
    "file_path_2021 = 'final_2021.csv'\n",
    "file_path_2022 = 'final_2022.csv'\n",
    "file_path_2023 = 'final_2023.csv'\n",
    "\n",
    "cleaned_data_2021 = pd.read_csv(file_path_2021)\n",
    "cleaned_data_2022 = pd.read_csv(file_path_2022)\n",
    "cleaned_data_2023 = pd.read_csv(file_path_2023)\n",
    "\n",
    "# Concatenate the datasets\n",
    "combined_data = pd.concat([cleaned_data_2021, cleaned_data_2022, cleaned_data_2023])\n",
    "\n",
    "# Save the combined dataset to a new CSV file\n",
    "combined_file_path = 'combined_data_2021_2022_2023.csv'\n",
    "combined_data.to_csv(combined_file_path, index=False)\n",
    "\n",
    "print(\"Combined dataset saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7d1ec-c2f5-4008-b880-4b51eba82c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
